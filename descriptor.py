import itertoolsfrom collections import OrderedDict, Sequencefrom copy import deepcopyfrom inspect import isclass, signaturefrom decereb.masker import DummyMasker, MultiRoiMaskerfrom sklearn.base import BaseEstimatorfrom sklearn.kernel_ridge import KernelRidgefrom .util.sequences import flattenfrom decereb.pipeline import Chain, Linkclass Struct(dict):    def __init__(self, child_init):        kwargs = signature(child_init).parameters.items()        super().__init__(kwargs)    def __getitem__(self, key):        if key not in self.keys():            raise KeyError('No such attribute')        return getattr(self, key)    def __setitem__(self, key, value):        # if key not in self.keys():        #     raise KeyError('No such attribute')        super().__setattr__(key, value)        super().__setitem__(key, value)    def __setattr__(self, key, value):        # if key not in self.keys():        #     raise KeyError('No such attribute')        super().__setattr__(key, value)        super().__setitem__(key, value)    def __delitem__(self, *args, **kwargs):        super().__delattr__(*args, **kwargs)        super().__delitem__(*args, **kwargs)    def update(self, *args, **kwargs):        for arg in args:            for key, value in arg:                super().__setattr__(key, value)                super().__setitem__(key, value)        for key, value in kwargs.items():            super().__setattr__(key, value)            super().__setitem__(key, value)class Data(Struct):    def __init__(self, name=None, data=None, mask=None, labels=None, subjects=None, feature_names=None, label_names=None):        super().__init__(self.__init__)        self.name = name        self.data = data        self.mask = mask        self.labels = labels        self.subjects = subjects        self.feature_names = feature_names        self.label_names = label_namesclass Channel(Struct):    clfs = None    fss = None    def __init__(self, clf_names=None, fs_names=None):        super().__init__(self.__init__)        self.clf = list(DescriptorConcatenator(self.clfs, clf_names if isinstance(clf_names, (list, tuple)) else [clf_names]))        if fs_names is None:            self.fs = None        else:            self.fs = list(DescriptorConcatenator(self.fss, fs_names if isinstance(fs_names, (list, tuple)) else [fs_names]))    @staticmethod    def init_channel(clfs=None, fss=None):        Channel.clfs = clfs        Channel.fss = fssclass ChainBuilder(object):    schemes = None    def __init__(self, scheme_names=None):        self.scheme_names = scheme_names    def build_chain(self, select_indices=None):        selected_schemes = list(DescriptorConcatenator(descriptor_list=self.schemes, base_names=self.scheme_names))        if select_indices is None:            select_indices = range(len(selected_schemes))        elif not isinstance(select_indices, Sequence):            select_indices = [select_indices]        linkdef_list = []        for i, scheme in zip(select_indices, selected_schemes):            linkdef_list.append(Link(scheme=scheme))        return Chain(linkdef_list)    @staticmethod    def init_chain_builder(schemes):        ChainBuilder.schemes = schemesclass DescriptorConcatenator:    def __init__(self, descriptor_list=None, base_names=None, con_names=None):        self.descriptor_list = descriptor_list        # if isinstance(flatten(self.descriptor_list)[0], InputDescriptor):        #     self.base_descriptors = flatten([[[d for d in itertools.product(*dlist)] for dlist in self.descriptor_list        #                                       if flatten(dlist)[0].name == k] for k in base_names], seq_type=list)        # else:        self.base_descriptors = sum(sum([[list(d) for d in self.descriptor_list if d.name == k] for k in base_names], []), [])        if con_names is not None:            self.connections = sum(sum([[list(d) for d in self.descriptor_list if d.name == k] for k in con_names], []), [])        else:            self.connections = None    def __iter__(self):        if self.connections is not None:            n = len(self.connections)            perms = [c for i in range(n + 1) for c in itertools.combinations(range(n), i)]            lst = sum([[tuple([deepcopy(base)] + list(deepcopy(con))) for con in itertools.product(*[self.connections[i] for i in p])]                        for p in perms for base in self.base_descriptors], [])            for l in lst:                if len(l) > 1:                    for i, descriptor in enumerate(l):                        new_identifier = OrderedDict()                        for k in descriptor.identifier.keys():                            new_key = '%s%g_%s' % (descriptor.prefix, i, k.split(descriptor.prefix + '_', 1)[1])                            new_identifier[new_key] = descriptor.identifier[k]                        descriptor.identifier = new_identifier        else:            lst = self.base_descriptors        for i, descriptor in enumerate(lst):            if isinstance(descriptor, Sequence):                for d in descriptor:                    d.identifier['%s_id' % d.prefix] = i            else:                descriptor.identifier['%s_id' % descriptor.prefix] = i        for l in lst:            yield lclass MetaDescriptor:    def __init__(self):        self.identifier_exceptions = []        self.iterator_exceptions = []        self.iterator_list = []        self.identifier = None    def __iter__(self):        list_args = sum([[(i, k) for k, v in iterator.items() if isinstance(v, list) and k not in self.iterator_exceptions]                         for i, iterator in enumerate(self.iterator_list)], [])        if True in [len(la) > 0 for la in list_args]:            instances = []            perms = [list(p) for p in                     list(itertools.product(*[[(i, la, j) for j in self.iterator_list[i][la]] for i, la in list_args]))]            for perm in perms:                instance = deepcopy(self)                for p in perm:                    instance.iterator_list[p[0]].update([p[1:]])                instance.build_identifier()                instances.append(instance)        else:            instances = [self]        for instance in instances:            yield instance    def build_identifier(self):        identifiers = []        for identifier in self.identifier_list:            if issubclass(identifier.__class__, dict):                identifiers += [(self.prefix + '_' + k, v) for k, v in identifier.items() if k not in self.identifier_exceptions]            elif isinstance(identifier, Sequence):                for i, identifier_ in enumerate(identifier):                    identifiers += [(str(i) + '_' + self.prefix + '_' + k, v) for k, v in identifier_.items() if k not in self.identifier_exceptions]                    # identifiers += [(self.prefix + '_' + k, v) for k, v in identifier_.items() if k not in self.identifier_exceptions]        self.identifier = OrderedDict(identifiers)        for k, v in self.identifier.items():            if isinstance(v, (list, dict)):                self.identifier[k] = str(v)            elif isclass(v):                self.identifier[k] = str(v).split('.')[-1][:-2]            elif hasattr(v, '__class__') and issubclass(v.__class__, BaseEstimator):                self.identifier[k] = str(v)class SchemeDescriptor(MetaDescriptor):    def __init__(self, name=None, data=None, masker=None, masker_args=None, pipeline=None,                 clf_multiroi=None, clf_multiroi_args=None, clf_meta_args=None, identifier=None):        super().__init__()        self.name = name        self.prefix = 'in'        self.clf_meta_args = clf_meta_args        self.data = self.set_variable(data)        self.pipeline = self.set_variable(pipeline)        self.n_channels = len(self.pipeline)        self.masker = self.set_variable(masker, default=DummyMasker)        self.masker_args = self.set_variable(masker_args, default=dict())        self.is_multiroi = [issubclass(m, MultiRoiMasker) for m in self.masker]        self.clf_multiroi = self.set_variable(clf_multiroi)        # if self.clf_multiroi is None:        #     self.clf_multiroi_args = clf_multiroi_args        # else:        #     self.clf_multiroi_args = self.set_variable(clf_multiroi_args, default=dict(), multi_channel=False)        self.clf_multiroi_args = self.set_variable(clf_multiroi_args, default=dict())        for c, channel in enumerate(self.pipeline):            # make sure feature selection is always a tuple            if channel.fs:                for f, fs in enumerate(channel.fs):                    if not isinstance(fs, tuple):                        self.pipeline[c].fs[f] = (fs, )            # elif isinstance(channel.fs, Sequence):            #     self.pipeline[c].fs = None            # set up special case of searchlight ensemble            for e, clf in enumerate(channel.clf):                if clf.clf._estimator_type == 'searchlight_ensemble':                    if not 'base_estimator_args' in clf.clf_args:                        clf.clf_args['base_estimator_args'] = dict()                    # clf.clf_args['base_estimator_args'].update(mask_img=self.data[c].mask)                    clf.clf_args.update(mask_img=self.data[c].mask)                    self.masker_args[c].update(searchlight=True)        self.iterator_list = [self.masker_args, self.pipeline]        self.iterator_exceptions = ['rois']        self.identifier_list = [dict(name=name), [{'multiroi': v} for v in self.is_multiroi], self.masker_args,                                self.clf_multiroi_args, OrderedDict([('data_name', d.name) for d in self.data]),                                identifier]        self.identifier_exceptions = ['rois', 'mask_img']        self.build_identifier()        # analysis_def.clf_args['base_estimator_args'].update(mask_img=scheme.data.mask)    def __iter__(self):        list_args = flatten([[[(i, c, k) for k, v in channel.items() if isinstance(v, list) and k not in self.iterator_exceptions]                              for c, channel in enumerate(iterator)] for i, iterator in enumerate(self.iterator_list)], seq_type=list)        if True in [len(la) > 0 for la in list_args]:            instances = []            perms = [list(p) for p in list(itertools.product(*[[(i, c, la, j)                     for j in self.iterator_list[i][c][la]] for i, c, la in list_args]))]            for perm in perms:                perm_names = [p[2] for p in perm]                valid = True                if 'fs' in perm_names and [fs.name for fs in perm[perm_names.index('fs')][-1]] != [None]:                    incomp = perm[perm_names.index('clf')][-1].fs_incompatible                    fs_list = [fs.name for fs in perm[perm_names.index('fs')][-1]]                    if incomp is True or (isinstance(incomp, list) and bool(set(fs_list) & set(incomp))):                        valid = False                if valid:                    instance = deepcopy(self)                    for p in perm:                        instance.iterator_list[p[0]][p[1]].update([p[2:]])                    instance.build_identifier()                    instances.append(instance)        else:            instances = [self]        for instance in instances:            yield instance    def set_variable(self, variable, default=None, multi_channel=True):        if variable is None:            if multi_channel:                return_variable = [deepcopy(default) for _ in range(self.n_channels)]            else:                return_variable = default        else:            if not isinstance(variable, Sequence):                variable = [variable]            return_variable = [el if el is not None else deepcopy(default) for el in variable]        return return_variableclass FeatureSelectionDescriptor(MetaDescriptor):    def __init__(self, name=None, fs_args=None, identifier=None):        super().__init__()        self.name = name        self.fs_args = fs_args        self.prefix = 'fs'        if fs_args is not None:            self.iterator_list += [self.fs_args]            if 'model_args' in fs_args:                self.iterator_list += [self.fs_args['model_args']]        self.identifier_exceptions = ['model_args']        self.identifier_list = [dict(type=self.name), *self.iterator_list, identifier]        self.build_identifier()class ClassifierDescriptor(MetaDescriptor):    def __init__(self, name=None, clf=None, clf_args=None, identifier=None, fs_incompatible=False, seed_list=None):        super().__init__()        self.name = name        self.clf = clf        if clf_args is None:            self.clf_args = dict()        else:            self.clf_args = clf_args        self.fs_incompatible = fs_incompatible if isinstance(fs_incompatible, (list, bool)) else [fs_incompatible]        self.seed_list = [None] if seed_list is None else seed_list        if hasattr(self.clf, '_estimator_type') and self.clf._estimator_type in ['regressor', 'classifier']:            if self.clf._estimator_type == 'regressor':                self.regression = True            else:                self.regression = False        elif hasattr(self.clf, '_estimator_type') and self.clf._estimator_type in ['ensemble', 'searchlight_ensemble']:            if 'base_estimator' in self.clf_args:                if self.clf_args['base_estimator']._estimator_type == 'regressor':                    self.regression = True                else:                    self.regression = False            else:                if signature(self.clf).parameters['base_estimator'].default._estimator_type == 'regressor':                    self.regression = True                else:                    self.regression = False        elif self.clf.__name__ == 'SearchLight':            if self.clf_args['estimator'] == 'svc':                self.regression = False                self.clf._estimator_type = 'classifier'            else:                self.regression = True                self.clf._estimator_type = 'regressor'        else:            raise ValueError('Classifier type is not specified (regression or classification?)')        self.prefix = 'clf'        if clf_args is not None:            self.iterator_list += [self.clf_args]        self.iterator_exceptions = ['seed_list']        self.identifier_list = [dict(clf=str(self.clf).split('.')[-1][:-2]), *self.iterator_list,                                dict(regression=self.regression), dict(seed_list=self.seed_list), identifier]        self.identifier_exceptions = ['seed_list']        self.build_identifier()