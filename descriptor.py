import itertoolsfrom collections import OrderedDictfrom copy import deepcopyfrom inspect import isclass, signaturefrom sklearn.base import BaseEstimatorfrom sklearn.svm import SVCfrom .util.sequences import flattenfrom .util.various import datetime_microsecondsfrom .masker import DummyMasker, MultiRoiMaskerimport numpy as npclass Struct(dict):    def __init__(self):        """ Data structure that allows access to attributes both via keys and attributes AND is        compatible with multiprocessing_on_dill.        """        super().__init__()    def __getitem__(self, key):        if key not in self.keys():            raise KeyError('No attribute %s' % key)        return getattr(self, key)    def __setitem__(self, key, value):        super().__setattr__(key, value)        super().__setitem__(key, value)    def __setattr__(self, key, value):        super().__setattr__(key, value)        super().__setitem__(key, value)    def __delitem__(self, *args, **kwargs):        super().__delattr__(*args, **kwargs)        super().__delitem__(*args, **kwargs)    def update(self, *args, **kwargs):        for arg in args:            for key, value in arg:                super().__setattr__(key, value)                super().__setitem__(key, value)        for key, value in kwargs.items():            super().__setattr__(key, value)            super().__setitem__(key, value)    def __iter__(self):        for key in self.keys():            yield key    def keys(self):        return [key for key in super().keys()]    def items(self):        return [(key, value) for key, value in super().items()]    def __repr__(self):        string_ = 'Struct object('        at_least_one_element = False        for key, value in super().items():            string_ += '%s: %s, ' % (key, value)            at_least_one_element = True        if at_least_one_element:            string_ = string_[:-2]        string_ += ')'        return string_class Data(Struct):    optional_info_items = ['labels', 'subjects', 'feature_names', 'label_names']    def __init__(self, data, labels, name='data', has_time=False, mask=None, subjects=None,                 feature_names=None, label_names=None):        """ Object to define the data input        Parameters        ----------        data : data            data (e.g. subject x feature matrix, or List<NiftiImages>        name : str            identifying name for the data definition        mask : str            path to a mask file, which can be optionally used to mask data in the NiftiImages format        labels : List<int>            provide one label per subject. In a patient/control case, patient should be 1, control            should be 0.        subjects : List<str, int>            provide identifying information for each subject        feature_names : List<str>            provide identifiying names for each feature        label_names : List<str>            provide identifying names for each integer label        """        super().__init__()        self.name = name        self.data = data        self.has_time = has_time        self.mask = mask        self.labels = labels        self.subjects = subjects        self.feature_names = feature_names        self.label_names = label_names    @property    def data(self):        return self._data    @data.setter    def data(self, value):        self._data = valueclass Channel(Struct):    clf_pool = None    fs_pool = None    def __init__(self, fss=None, clfs=None, ):        """ A channel describes a processing modality, which can be combined to provide a majority        vote across modalities.        Parameters        ----------        fss : str, List<str>, decereb.descriptor.FeatureSelectionDescriptor,              List<decereb.descriptor.FeatureSelectionDescriptor>        clfs : str, List<str>, decereb.descriptor.ClassifierDescriptor,               List<decereb.descriptor.ClassifierDescriptor>        """        super().__init__()        self.set_fss(fss)        self.set_clfs(clfs)    def set_clfs(self, value):        clf_list = value if isinstance(value, (list, tuple)) else [value]        if isinstance(clf_list[0], ClassifierDescriptor):            Channel.clf_pool = clf_list            clf_list = [v.name for v in clf_list]        elif isinstance(value[0], str):            if self.clf_pool is None:                raise ValueError('Selection by name requires prior initialization of the '                                 'classifier pool.')            else:                clf_list = value        self.clfs = list(DescriptorConcatenator(self.clf_pool, clf_list))    def set_fss(self, value):        if value is None:            self.fss = None        else:            fs_list = value if isinstance(value, (list, tuple)) else [value]            if isinstance(fs_list[0], FeatureSelectionDescriptor):                Channel.fs_pool = fs_list                fs_list = [v.name for v in fs_list]            elif isinstance(value[0], str):                if self.fs_pool is None:                    raise ValueError('Selection by name requires prior initialization of the '                                     'feature selection pool.')                else:                    fs_list = value            self.fss = list(DescriptorConcatenator(self.fs_pool, fs_list))    @staticmethod    def init_channel(clfs=None, fss=None):        """ Initialize a channel.        Parameters        ----------        clfs : List<decereb.descriptor.ClassifierDescriptor>        fss : List<decereb.descriptor.FeatureSelectionDescriptor>        """        Channel.clf_pool = clfs        Channel.fs_pool = fssclass DescriptorConcatenator:    def __init__(self, descriptor_list, base_names, con_names=None):        """        Parameters        ----------        descriptor_list : List<decereb.descriptor.[ClassDerivingFromMetaDescriptor]>        base_names : List<str>            List of descriptor names that should be selected from the descriptor list        con_names : List<str>            [TODO: is this still used?]        """        self.descriptor_list = descriptor_list if isinstance(descriptor_list, (list, tuple)) \            else [descriptor_list]        if not isinstance(base_names, (list, tuple)):            base_names = [base_names]        self.base_descriptors = sum(sum([[list(d) for d in self.descriptor_list if d.name == k]                                         for k in base_names], []), [])        if con_names is not None:            self.connections = sum(sum([[list(d) for d in self.descriptor_list if d.name == k]                                        for k in con_names], []), [])        else:            self.connections = None    def __iter__(self):        """ Iteration over the DescriptorConcatenator returns all combinations of different        descriptor types.        """        if self.connections is not None:            n = len(self.connections)            perms = [c for i in range(n + 1) for c in itertools.combinations(range(n), i)]            lst = sum([[tuple([deepcopy(base)] + list(deepcopy(con)))                        for con in itertools.product(*[self.connections[i] for i in p])]                       for p in perms for base in self.base_descriptors], [])            for l in lst:                if len(l) > 1:                    for i, descriptor in enumerate(l):                        new_identifier = OrderedDict()                        for k in descriptor.identifier.keys():                            new_key = '%s%g_%s' % \                                      (descriptor._prefix, i, k.split(descriptor._prefix + '_', 1)[1])                            new_identifier[new_key] = descriptor.identifier[k]                        descriptor.identifier = new_identifier        else:            lst = self.base_descriptors        for i, descriptor in enumerate(lst):            if isinstance(descriptor, (list, tuple)):                for d in descriptor:                    d.identifier['%s_id' % d._prefix] = i            else:                descriptor.identifier['%s_id' % descriptor._prefix] = i        for l in lst:            yield lclass Descriptor:    def __init__(self):        """ Parent class for all Descriptor objects        """        self.identifier_exceptions = []        self.iterator_exceptions = []        self.iterator_list = []        self.identifier = None    def __iter__(self):        """ Iteration over the Descriptor returns all combinations of Descriptor        definitions that were provided as Lists.        """        list_args = sum([[(i, k) for k, v in iterator.items()                          if isinstance(v, list) and k not in self.iterator_exceptions]                         for i, iterator in enumerate(self.iterator_list)], [])        if True in [len(la) > 0 for la in list_args]:            instances = []            perms = [list(p) for p in                     list(itertools.product(*[[(i, la, j) for j in self.iterator_list[i][la]]                                              for i, la in list_args]))]            for perm in perms:                instance = deepcopy(self)                for p in perm:                    instance.iterator_list[p[0]].update([p[1:]])                instance.build_identifier()                instances.append(instance)        else:            instances = [self]        for instance in instances:            yield instance    def build_identifier(self):        """ Build identifier, which is a list of (key, value), which is used to generate a        description for the Descriptor (e.g. for database storage)        """        identifiers = []        for identifier in self.identifier_list:            if issubclass(identifier.__class__, dict):                identifiers += [(self._prefix + '_' + k, v) for k, v in identifier.items()                                if k not in self.identifier_exceptions]            elif isinstance(identifier, (list, tuple)):                for i, identifier_ in enumerate(identifier):                    number_prefix = '' if len(identifier) == 1 else str(i) + '_'                    identifiers += [(number_prefix + self._prefix + '_' + k, v)                                    for k, v in identifier_.items()                                    if k not in self.identifier_exceptions]        self.identifier = OrderedDict(identifiers)        for k, v in self.identifier.items():            if isinstance(v, (list, dict)):                self.identifier[k] = str(v)            elif isclass(v):                self.identifier[k] = str(v).split('.')[-1][:-2]            elif hasattr(v, '__class__') and issubclass(v.__class__, BaseEstimator):                self.identifier[k] = str(v)class SchemeDescriptor(Descriptor):    def __init__(self, data, name=None, masker=None, masker_args=None, channels=None, clf_multiroi=None,                 clf_multiroi_args=None, clf_meta_args=None, cv=None, scoring=None):        """ Definition of a data processing scheme.        Parameters        ----------        data : decereb.descriptor.Data            Data on which the scheme is based        name : str            Identifying name for the scheme        masker : (List of) object(s) deriving from nilearn.input_data.base_masker.BaseMasker        masker_args : (List of) dict            Arguments to be passed to the masker        channels : decereb.descriptor.Channel,  List<decereb.descriptor.Channel>            (List of) processing channel(s)        clf_multiroi : object deriving from sklearn.ensemble.base.BaseEnsemble            Ensemble classifier in case of multiple ROIs        clf_multiroi_args : (List of) dict            Arguements to be passed to the multiroi ensemble classifier        clf_meta_args : dict            Arguments to be passed for the meta-classification across channels [TODO!!]        cv : object            cross validation object: a generator returning (train_indices, test_indices)                                     in each iteration        scoring : str        """        super().__init__()        self.name = name        self._prefix = 'in'        self.clf_meta_args = clf_meta_args        self.data = self.set_attribute(data)        self.channels = self.set_attribute(channels)        self.n_channels = len(self.channels)        self.masker = self.set_attribute(masker, default=DummyMasker)        self.masker_args = self.set_attribute(masker_args, default=dict())        self.cv = cv        self.is_multiroi = [issubclass(m, MultiRoiMasker) for m in self.masker]        self.clf_multiroi = self.set_attribute(clf_multiroi)        self.scoring = scoring        self.clf_multiroi_args = self.set_attribute(clf_multiroi_args, default=dict())        for c, channel in enumerate(self.channels):            if 'rois' in self.masker_args[c] and not isinstance(self.masker_args[c]['rois'], (list, tuple)):                self.masker_args[c]['rois'] = [self.masker_args[c]['rois']]            # make sure feature selection is always a tuple            if channel.fss:                for f, fs in enumerate(channel.fss):                    if not isinstance(fs, tuple):                        self.channels[c].fss[f] = (fs,)            # set up special case of searchlight ensemble            for e, clf in enumerate(channel.clfs):                if clf.clf._estimator_type == 'searchlight_ensemble':                    if not 'base_estimator_args' in clf.clf_args:                        clf.clf_args['base_estimator_args'] = dict()                    clf.clf_args.update(mask_img=self.data[c].mask)                    self.masker_args[c].update(searchlight=True)        self.iterator_list = [self.masker_args, self.channels]        self.iterator_exceptions = ['rois']        self.identifier_list = [dict(name=name),                                [{'multiroi': v} for v in self.is_multiroi],                                self.masker_args,                                self.clf_multiroi_args,                                OrderedDict([('data_name', d.name) for d in self.data])]        self.identifier_exceptions = ['rois', 'mask_img']        self.build_identifier()    def __iter__(self):        """ Jesus..        """        list_args = flatten([[[(i, c, k) for k, v in channel.items()                               if isinstance(v, list) and k not in self.iterator_exceptions]                              for c, channel in enumerate(iterator)]                             for i, iterator in enumerate(self.iterator_list)], seq_type=list)        if True in [len(la) > 0 for la in list_args]:            instances = []            perms = [list(p) for p in list(itertools.product(*[[(i, c, la, j)                     for j in self.iterator_list[i][c][la]] for i, c, la in list_args]))]            for perm in perms:                perm_names = [p[2] for p in perm]                valid = True                if 'fs' in perm_names \                        and [fs.name for fs in perm[perm_names.index('fs')][-1]] != [None]:                    incomp = perm[perm_names.index('clf')][-1].fs_incompatible                    fs_list = [fs.name for fs in perm[perm_names.index('fs')][-1]]                    if incomp is True \                            or (isinstance(incomp, (tuple, list)) and bool(set(fs_list) & set(incomp))):                        valid = False                if valid:                    instance = deepcopy(self)                    for p in perm:                        instance.iterator_list[p[0]][p[1]].update([p[2:]])                    instance.build_identifier()                    instances.append(instance)        else:            instances = [self]        for instance in instances:            yield instance    def set_attribute(self, variable, default=None, multi_channel=True):        """ Very ugly function to set object attributes        """        if variable is None:            if multi_channel:                return_variable = [deepcopy(default) for _ in range(self.n_channels)]            else:                return_variable = default        else:            if not isinstance(variable, (list, tuple)):                variable = [variable]            return_variable = [el if el is not None else deepcopy(default) for el in variable]        return return_variableclass FeatureSelectionDescriptor(Descriptor):    def __init__(self, type, name=None, fs_args=None):        """ Definition of the feature selection        Parameters        ----------        name : None, str            Identifying name for the feature selection descriptor        type : None, str            Feature selection type [TODO: add list of possible strings]        fs_args :            Arguments for the feature selection (as defined by the name)        """        super().__init__()        self.type = type        self.name = name        self.fs_args = fs_args        self._prefix = 'fs'        self.identifier_exceptions = ['model_args']        self._build_identifier_list()        self.build_identifier()    @property    def name(self):        return self._name    @name.setter    def name(self, value):        if value is None:            self._name = self.type        else:            self._name = value    @property    def fs_args(self):        return self._fs_args    @fs_args.setter    def fs_args(self, value):        first_time_called = not hasattr(self, '_fs_args')        if value is None:            self._fs_args = dict()        else:            self._fs_args = value            self.iterator_list += [self._fs_args]            if 'model_args' in self._fs_args:                self.iterator_list += [self.fs_args['model_args']]        if not first_time_called:            self._build_identifier_list()            self.build_identifier()    def _build_identifier_list(self):        self.identifier_list = [dict(type=self.type, name=self.name), *self.iterator_list]class ClassifierDescriptor(Descriptor):    def __init__(self, name, clf=SVC, clf_args=None, fs_incompatible=('',),                 seed_list=None):        """ Definition of the classifier        Parameters        ----------        name : str            Identifying name for the classifier descriptor        clf : classifier class            Uninitialized class of the classifier (e.g. sklearn.svm.LinearSVC)        clf_args : dict            Arguments to be passed to the classifier        fs_incompatible : str, Tuple<str>            (Tuple of) String(s) that specifies incompatible feature selection descriptors by name        seed_list : List<int>, None            List of seeds that should be looped over        """        super().__init__()        self._clf_string = str(clf)[8:-2]        self.clf_args = clf_args        self.clf = clf        self.name = name        self.fs_incompatible = fs_incompatible        self.seed_list = seed_list        self._prefix = 'clf'        self.iterator_exceptions = ['seed_list']        self.identifier_exceptions = ['seed_list']        self._build_identifier_list()        self.build_identifier()    @property    def name(self):        return self._name    @name.setter    def name(self, value):        if value is None:            self._name = self._clf_string + '_' + datetime_microseconds()        else:            self._name = value    @property    def seed_list(self):        return self._seed_list    @seed_list.setter    def seed_list(self, value):        first_time_called = not hasattr(self, '_seed_list')        self._seed_list = value if isinstance(value, (list, tuple, range)) else [value]        self.n_seeds = None if self._seed_list is [None] else len(self._seed_list)        if not first_time_called:            self._build_identifier_list()            self.build_identifier()    @property    def clf(self):        return self._clf    @clf.setter    def clf(self, value):        first_time_called = not hasattr(self, '_clf')        self._clf = value        self._searchlight = 'SearchLight' in str(self._clf)        if hasattr(self._clf, '_estimator_type') \                and self._clf._estimator_type in ['regressor', 'classifier']:            if self._clf._estimator_type == 'regressor':                self.regression = True            else:                self.regression = False        elif hasattr(self._clf, '_estimator_type') \                and self._clf._estimator_type in ['ensemble', 'searchlight_ensemble']:            if 'base_estimator' in self.clf_args:                if self._clf_args['base_estimator']._estimator_type == 'regressor':                    self.regression = True                else:                    self.regression = False            else:                default_estimator_type = signature(self._clf).parameters['base_estimator'].default._estimator_type                if default_estimator_type == 'regressor':                    self.regression = True                else:                    self.regression = False        elif hasattr(self._clf, '_estimator_type') and self._clf._estimator_type == 'distance':            self.regression = False        elif self._clf.__name__ == 'SearchLight':            if 'estimator' not in self._clf_args or self._clf_args['estimator'] == 'svc':                self.regression = False                self._clf._estimator_type = 'classifier'            else:                self.regression = True                self._clf._estimator_type = 'regressor'        else:            raise ValueError('Classifier type is not specified (regression or classification?)')        if not first_time_called:            self._build_identifier_list()            self.build_identifier()    @property    def clf_args(self):        return self._clf_args    @clf_args.setter    def clf_args(self, value):        first_time_called = not hasattr(self, '_clf_args')        if value is None:            self._clf_args = dict()        else:            self._clf_args = value            self.iterator_list += [self._clf_args]        if not first_time_called:            self._build_identifier_list()            self.build_identifier()    @property    def fs_incompatible(self):        return self._fs_incompatible    @fs_incompatible.setter    def fs_incompatible(self, value):        if isinstance(value, (list, tuple)):            self._fs_incompatible = value        else:            self._fs_incompatible = (value, )    def _build_identifier_list(self):        self.identifier_list = [dict(name=self.name, clf=self._clf_string, n_seeds=self.n_seeds,                                     seed_list=self.seed_list, regression=self.regression),                                *self.iterator_list]