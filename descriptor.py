import itertoolsfrom collections import OrderedDict, Sequencefrom copy import deepcopyfrom inspect import isclass, signaturefrom sklearn.base import BaseEstimatorfrom sklearn.svm import SVCfrom .util.sequences import flattenfrom .util.various import datetime_microsecondsfrom .masker import DummyMasker, MultiRoiMaskerclass Struct(dict):    def __init__(self, child_init):        """ Data structure that allows access to attributes both via keys and attributes AND is        compatible with multiprocessing_on_dill.        Parameters        ----------        child_init: object            child object that derives from Struct        """        kwargs = signature(child_init).parameters.items()        super().__init__(kwargs)    def __getitem__(self, key):        if key not in self.keys():            raise KeyError('No such attribute')        return getattr(self, key)    def __setitem__(self, key, value):        super().__setattr__(key, value)        super().__setitem__(key, value)    def __setattr__(self, key, value):        super().__setattr__(key, value)        super().__setitem__(key, value)    def __delitem__(self, *args, **kwargs):        super().__delattr__(*args, **kwargs)        super().__delitem__(*args, **kwargs)    def update(self, *args, **kwargs):        for arg in args:            for key, value in arg:                super().__setattr__(key, value)                super().__setitem__(key, value)        for key, value in kwargs.items():            super().__setattr__(key, value)            super().__setitem__(key, value)class Data(Struct):    optional_info_items = ['labels', 'subjects', 'feature_names', 'label_names']    def __init__(self, data, labels, name='data', mask=None, subjects=None,                 feature_names=None, label_names=None):        """ Object to define the data input        Parameters        ----------        data : data            data (e.g. subject x feature matrix, or List<NiftiImages>        name : str            identifying name for the data definition        mask : str            path to a mask file, which can be optionally used to mask data in the NiftiImages format        labels : List<int>            provide one label per subject. In a patient/control case, patient should be 1, control            should be 0.        subjects : List<str, int>            provide identifying information for each subject        feature_names : List<str>            provide identifiying names for each feature        label_names : List<str>            provide identifying names for each integer label        """        super().__init__(self.__init__)        self.name = name        self.data = data        self.mask = mask        self.labels = labels        self.subjects = subjects        self.feature_names = feature_names        self.label_names = label_namesclass Channel(Struct):    clfs = None    fss = None    def __init__(self, clf_names=None, fs_names=None):        """ A channel describes a processing modality, which can be combined to provide a majority        vote across modalities.        Parameters        ----------        clf_names : List<str>            a list of classifier strings that should be selected from Channel.clfs        fs_names : List<str>            a list of feature selection strings that should be selected from Channel.fss        """        super().__init__(self.__init__)        self.clf_names = clf_names        self.fs_names = clf_names        clf_list = clf_names if isinstance(clf_names, Sequence) else [self.clf_names]        self.clf = list(DescriptorConcatenator(self.clfs, clf_list))        if fs_names is None:            self.fs = None        else:            fs_list = fs_names if isinstance(fs_names, Sequence) else [fs_names]            self.fs = list(DescriptorConcatenator(self.fss, fs_list))    @staticmethod    def init_channel(clfs=None, fss=None):        """ Initialize a channel.        Parameters        ----------        clfs : List<decereb.descriptor.ClassifierDescriptor>        fss : List<decereb.descriptor.FeatureSelectionDescriptor>        """        Channel.clfs = clfs        Channel.fss = fssclass DescriptorConcatenator:    def __init__(self, descriptor_list, base_names, con_names=None):        """        Parameters        ----------        descriptor_list : List<decereb.descriptor.[ClassDerivingFromMetaDescriptor]>        base_names : List<str>            List of descriptor names that should be selected from the descriptor list        con_names : List<str>            [TODO: is this still used?]        """        self.descriptor_list = descriptor_list if isinstance(descriptor_list, (list, tuple)) \            else [descriptor_list]        if not isinstance(base_names, (list, tuple)):            base_names = [base_names]        self.base_descriptors = sum(sum([[list(d) for d in self.descriptor_list if d.name == k]                                         for k in base_names], []), [])        if con_names is not None:            self.connections = sum(sum([[list(d) for d in self.descriptor_list if d.name == k]                                        for k in con_names], []), [])        else:            self.connections = None    def __iter__(self):        """ Iteration over the DescriptorConcatenator returns all combinations of different        descriptor types.        """        if self.connections is not None:            n = len(self.connections)            perms = [c for i in range(n + 1) for c in itertools.combinations(range(n), i)]            lst = sum([[tuple([deepcopy(base)] + list(deepcopy(con)))                        for con in itertools.product(*[self.connections[i] for i in p])]                       for p in perms for base in self.base_descriptors], [])            for l in lst:                if len(l) > 1:                    for i, descriptor in enumerate(l):                        new_identifier = OrderedDict()                        for k in descriptor.identifier.keys():                            new_key = '%s%g_%s' % \                                      (descriptor._prefix, i, k.split(descriptor._prefix + '_', 1)[1])                            new_identifier[new_key] = descriptor.identifier[k]                        descriptor.identifier = new_identifier        else:            lst = self.base_descriptors        for i, descriptor in enumerate(lst):            if isinstance(descriptor, Sequence):                for d in descriptor:                    d.identifier['%s_id' % d._prefix] = i            else:                descriptor.identifier['%s_id' % descriptor._prefix] = i        for l in lst:            yield lclass Descriptor:    def __init__(self):        """ Parent class for all Descriptor objects        """        self.identifier_exceptions = []        self.iterator_exceptions = []        self.iterator_list = []        self.identifier = None    def __iter__(self):        """ Iteration over the Descriptor returns all combinations of Descriptor        definitions that were provided as Lists.        """        list_args = sum([[(i, k) for k, v in iterator.items()                          if isinstance(v, list) and k not in self.iterator_exceptions]                         for i, iterator in enumerate(self.iterator_list)], [])        if True in [len(la) > 0 for la in list_args]:            instances = []            perms = [list(p) for p in                     list(itertools.product(*[[(i, la, j) for j in self.iterator_list[i][la]]                                              for i, la in list_args]))]            for perm in perms:                instance = deepcopy(self)                for p in perm:                    instance.iterator_list[p[0]].update([p[1:]])                instance.build_identifier()                instances.append(instance)        else:            instances = [self]        for instance in instances:            yield instance    def build_identifier(self):        """ Build identifier, which is a list of (key, value), which is used to generate a        description for the Descriptor (e.g. for database storage)        """        identifiers = []        for identifier in self.identifier_list:            if issubclass(identifier.__class__, dict):                identifiers += [(self._prefix + '_' + k, v) for k, v in identifier.items()                                if k not in self.identifier_exceptions]            elif isinstance(identifier, Sequence):                for i, identifier_ in enumerate(identifier):                    identifiers += [(str(i) + '_' + self._prefix + '_' + k, v)                                    for k, v in identifier_.items()                                    if k not in self.identifier_exceptions]        self.identifier = OrderedDict(identifiers)        for k, v in self.identifier.items():            if isinstance(v, (list, dict)):                self.identifier[k] = str(v)            elif isclass(v):                self.identifier[k] = str(v).split('.')[-1][:-2]            elif hasattr(v, '__class__') and issubclass(v.__class__, BaseEstimator):                self.identifier[k] = str(v)class SchemeDescriptor(Descriptor):    def __init__(self, name, data, masker=None, masker_args=None, channels=None,                 clf_multiroi=None, clf_multiroi_args=None, clf_meta_args=None, scoring=None):        """ Definition of a data processing scheme.        Parameters        ----------        name : str            Identifying name for the scheme        data : decereb.descriptor.Data            Data on which the scheme is based        masker : (List of) object(s) deriving from nilearn.input_data.base_masker.BaseMasker        masker_args : (List of) dict            Arguments to be passed to the masker        channels : decereb.descriptor.Channel,  List<decereb.descriptor.Channel>            (List of) processing channel(s)        clf_multiroi : object deriving from sklearn.ensemble.base.BaseEnsemble            Ensemble classifier in case of multiple ROIs        clf_multiroi_args : (List of) dict            Arguements to be passed to the multiroi ensemble classifier        clf_meta_args : dict            Arguments to be passed for the meta-classification across channels [TODO!!]        scoring : function            Function from sklearn.metrics or created via sklearn.metrics.make_scorer        """        super().__init__()        self.name = name        self._prefix = 'in'        self.clf_meta_args = clf_meta_args        self.data = self.set_attribute(data)        self.channels = self.set_attribute(channels)        self.n_channels = len(self.channels)        self.masker = self.set_attribute(masker, default=DummyMasker)        self.masker_args = self.set_attribute(masker_args, default=dict())        self.is_multiroi = [issubclass(m, MultiRoiMasker) for m in self.masker]        self.clf_multiroi = self.set_attribute(clf_multiroi)        self.scoring = scoring        self.clf_multiroi_args = self.set_attribute(clf_multiroi_args, default=dict())        for c, channel in enumerate(self.channels):            # make sure feature selection is always a tuple            if channel.fs:                for f, fs in enumerate(channel.fs):                    if not isinstance(fs, tuple):                        self.channels[c].fs[f] = (fs,)            # elif isinstance(channel.fs, Sequence):            #     self.pipeline[c].fs = None            # set up special case of searchlight ensemble            for e, clf in enumerate(channel.clf):                if clf.clf._estimator_type == 'searchlight_ensemble':                    if not 'base_estimator_args' in clf.clf_args:                        clf.clf_args['base_estimator_args'] = dict()                    # clf.clf_args['base_estimator_args'].update(mask_img=self.data[c].mask)                    clf.clf_args.update(mask_img=self.data[c].mask)                    self.masker_args[c].update(searchlight=True)        self.iterator_list = [self.masker_args, self.channels]        self.iterator_exceptions = ['rois']        self.identifier_list = [dict(name=name),                                [{'multiroi': v} for v in self.is_multiroi],                                self.masker_args,                                self.clf_multiroi_args,                                OrderedDict([('data_name', d.name) for d in self.data])]        self.identifier_exceptions = ['rois', 'mask_img']        self.build_identifier()    def __iter__(self):        """ Jesus..        """        list_args = flatten([[[(i, c, k) for k, v in channel.items()                               if isinstance(v, list) and k not in self.iterator_exceptions]                              for c, channel in enumerate(iterator)]                             for i, iterator in enumerate(self.iterator_list)], seq_type=list)        if True in [len(la) > 0 for la in list_args]:            instances = []            perms = [list(p) for p in list(itertools.product(*[[(i, c, la, j)                     for j in self.iterator_list[i][c][la]] for i, c, la in list_args]))]            for perm in perms:                perm_names = [p[2] for p in perm]                valid = True                if 'fs' in perm_names \                        and [fs.name for fs in perm[perm_names.index('fs')][-1]] != [None]:                    incomp = perm[perm_names.index('clf')][-1].fs_incompatible                    fs_list = [fs.name for fs in perm[perm_names.index('fs')][-1]]                    if incomp is True \                            or (isinstance(incomp, list) and bool(set(fs_list) & set(incomp))):                        valid = False                if valid:                    instance = deepcopy(self)                    for p in perm:                        instance.iterator_list[p[0]][p[1]].update([p[2:]])                    instance.build_identifier()                    instances.append(instance)        else:            instances = [self]        for instance in instances:            yield instance    def set_attribute(self, variable, default=None, multi_channel=True):        """ Very ugly function to set object attributes        """        if variable is None:            if multi_channel:                return_variable = [deepcopy(default) for _ in range(self.n_channels)]            else:                return_variable = default        else:            if not isinstance(variable, Sequence):                variable = [variable]            return_variable = [el if el is not None else deepcopy(default) for el in variable]        return return_variableclass FeatureSelectionDescriptor(Descriptor):    def __init__(self, name=None, fs_args=None):        """ Definition of the feature selection        Parameters        ----------        name : None, str            Identifying name for the feature selection descriptor        fs_args :            Arguments for the feature selection (as defined by the name)        """        super().__init__()        self.name = name        self.fs_args = fs_args        self._prefix = 'fs'        self.identifier_exceptions = ['model_args']        self._build_identifier_list()        self.build_identifier()    @property    def fs_args(self):        return self._fs_args    @fs_args.setter    def fs_args(self, value):        first_time_called = not hasattr(self, '_fs_args')        if value is None:            self._fs_args = dict()        else:            self._fs_args = value            self.iterator_list += [self._fs_args]            if 'model_args' in self._fs_args:                self.iterator_list += [self.fs_args['model_args']]        if not first_time_called:            self._build_identifier_list()            self.build_identifier()    def _build_identifier_list(self):        self.identifier_list = [dict(type=self.name), *self.iterator_list]class ClassifierDescriptor(Descriptor):    def __init__(self, name=None, clf=SVC, clf_args=None, fs_incompatible=('',),                 seed_list=None):        """ Definition of the classifier        Parameters        ----------        name : str            Identifying name for the classifier descriptor        clf : classifier class            Uninitialized class of the classifier (e.g. sklearn.svm.LinearSVC)        clf_args : dict            Arguments to be passed to the classifier        fs_incompatible : str, Tuple<str>            (Tuple of) String(s) that specifies incompatible feature selection descriptors by name        seed_list : List<int>, None            List of seeds that should be looped over        """        super().__init__()        self._clf_string = str(clf)[8:-2]        self.clf_args = clf_args        self.clf = clf        self.name = name        self.fs_incompatible = fs_incompatible        self.seed_list = seed_list        self._prefix = 'clf'        self.iterator_exceptions = ['seed_list']        self.identifier_exceptions = ['seed_list']        self._build_identifier_list()        self.build_identifier()    @property    def name(self):        return self._name    @name.setter    def name(self, value):        if value is None:            self._name = self._clf_string + '_' + datetime_microseconds()        else:            self._name = value    @property    def clf(self):        return self._clf    @clf.setter    def clf(self, value):        first_time_called = not hasattr(self, '_clf')        self._clf = value        self._searchlight = 'SearchLight' in str(self._clf)        if hasattr(self._clf, '_estimator_type') \                and self._clf._estimator_type in ['regressor', 'classifier']:            if self._clf._estimator_type == 'regressor':                self.regression = True            else:                self.regression = False        elif hasattr(self._clf, '_estimator_type') \                and self._clf._estimator_type in ['ensemble', 'searchlight_ensemble']:            if 'base_estimator' in self.clf_args:                if self._clf_args['base_estimator']._estimator_type == 'regressor':                    self.regression = True                else:                    self.regression = False            else:                default_estimator_type = signature(self._clf).parameters['base_estimator'].default._estimator_type                if default_estimator_type == 'regressor':                    self.regression = True                else:                    self.regression = False        elif self._clf.__name__ == 'SearchLight':            if self._clf_args['estimator'] == 'svc':                self.regression = False                self._clf._estimator_type = 'classifier'            else:                self.regression = True                self._clf._estimator_type = 'regressor'        else:            raise ValueError('Classifier type is not specified (regression or classification?)')        if not first_time_called:            self._build_identifier_list()            self.build_identifier()    @property    def clf_args(self):        return self._clf_args    @clf_args.setter    def clf_args(self, value):        first_time_called = not hasattr(self, '_clf_args')        if value is None:            self._clf_args = dict()        else:            self._clf_args = value            self.iterator_list += [self._clf_args]        if not first_time_called:            self._build_identifier_list()            self.build_identifier()    @property    def fs_incompatible(self):        return self._fs_incompatible    @fs_incompatible.setter    def fs_incompatible(self, value):        if isinstance(value, (list, tuple)):            self._fs_incompatible = value        else:            self._fs_incompatible = (value, )    @property    def seed_list(self):        return self._seed_list    @seed_list.setter    def seed_list(self, value):        if value is None:            self._seed_list = [None]        else:            self._seed_list = value    def _build_identifier_list(self):        self.identifier_list = [dict(clf=self._clf_string), *self.iterator_list,                                dict(regression=self.regression), dict(seed_list=self.seed_list)]